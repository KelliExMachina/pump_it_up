{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, classification_report, f1_score, accuracy_score, roc_curve, roc_auc_score, mean_absolute_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = 'data/df_X.csv'\n",
    "df_independent = 'data/df_y.csv'\n",
    "\n",
    "df_X = pd.read_csv(df_features)\n",
    "df_y = pd.read_csv(df_independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55083, 27)\n",
      "(55083, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_X.shape)\n",
    "print(df_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder\n",
    "\n",
    "Converting the independent variable to numeric for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32259\n",
       "1    22824\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# BMG Encoder\n",
    "def bgm_encoder(element):\n",
    "    if element == 'functional':\n",
    "        return 0\n",
    "    elif element == 'non_functional':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df_y['status_group'] = df_y['status_group'].apply(bgm_encoder)\n",
    "df_y['status_group'].value_counts()\n",
    "# 0 = functional\n",
    "# 1 = non_functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "Now that there are no missing values, convert all of the categorical features into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_columns = ['funder', 'installer','management','management_group','extraction_type_group','extraction_type_class']\n",
    "df_X_categorical = df_X[encode_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following code was borrowed from our Seattle class lecture.  I tried to rewrite it, but it'sfunctional and efficient.  I'm going to rewrite this and combine with my other encoding functions as a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_concat_feature_train(df_X, feature_name):\n",
    "    \"\"\"\n",
    "    Helper function for transforming training data.  It takes in the full X dataframe and\n",
    "    feature name, makes a one-hot encoder, and returns the encoder as well as the dataframe\n",
    "    with that feature transformed into multiple columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # make a one-hot encoder and fit it to the training data\n",
    "    ohe = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\")\n",
    "    single_feature_df = df_X[[feature_name]]\n",
    "    ohe.fit(single_feature_df)\n",
    "    \n",
    "    # call helper function that actually encodes the feature and concats it\n",
    "    df_X = encode_and_concat_feature(df_X, feature_name, ohe)\n",
    "    \n",
    "    return ohe, df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_concat_feature(df_X, feature_name, ohe):\n",
    "    \"\"\"\n",
    "    Helper function for transforming a feature into multiple columns of 1s and 0s. Used\n",
    "    in both training and testing steps.  Takes in the full X dataframe, feature name, \n",
    "    and encoder, and returns the dataframe with that feature transformed into multiple\n",
    "    columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # create new one-hot encoded df based on the feature\n",
    "    single_feature_df = df_X[[feature_name]]\n",
    "    feature_array = ohe.transform(single_feature_df).toarray()\n",
    "    ohe_df = pd.DataFrame(feature_array, columns=ohe.categories_[0], index=df_X.index)\n",
    "    \n",
    "    # drop the old feature from X and concat the new one-hot encoded df\n",
    "    df_X = df_X.drop(feature_name, axis=1)\n",
    "    df_X = pd.concat([df_X, ohe_df], axis=1)\n",
    "    \n",
    "    return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "\n",
    "for categorical_feature in encode_columns:\n",
    "    ohe, df_X = encode_and_concat_feature_train(df_X, categorical_feature)\n",
    "    encoders[categorical_feature] = ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wpt_name', 'basin', 'region', 'lga', 'ward', 'extraction_type',\n",
      "       'water_quality', 'quantity', 'source', 'waterpoint_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_X_nonnumeric = df_X.select_dtypes('object')\n",
    "print(df_X_nonnumeric.columns)\n",
    "df_X_numeric = df_X.select_dtypes(exclude='object')\n",
    "\n",
    "X = df_X_numeric\n",
    "y = df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Spkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 44066\n",
      "y_train: 44066\n",
      "X_test: 11017\n",
      "y_test: 11017\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X_numeric, y, test_size=.2, random_state=42)\n",
    "print('X_train: {}'.format(len(X_train)))\n",
    "print('y_train: {}'.format(len(y_train)))\n",
    "print('X_test: {}'.format(len(X_test)))\n",
    "print('y_test: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_knn = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77     25700\n",
      "           1       0.68      0.60      0.64     18366\n",
      "\n",
      "    accuracy                           0.72     44066\n",
      "   macro avg       0.71      0.70      0.70     44066\n",
      "weighted avg       0.71      0.72      0.71     44066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_train_class_report = classification_report(y_train['status_group'], preds_knn[:, 1])\n",
    "print(knn_train_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_knn_test = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64      6559\n",
      "           1       0.44      0.40      0.42      4458\n",
      "\n",
      "    accuracy                           0.55     11017\n",
      "   macro avg       0.53      0.53      0.53     11017\n",
      "weighted avg       0.55      0.55      0.55     11017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_test_class_report = classification_report(y_test['status_group'], preds_knn_test[:, 1])\n",
    "print(knn_test_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit a baseline Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 1.59 s, total: 2min 29s\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dtc = DecisionTreeClassifier(max_depth=10)\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.3 s, sys: 44.4 s, total: 1min 18s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_dtc_train = dtc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82     25700\n",
      "           1       0.80      0.62      0.70     18366\n",
      "\n",
      "    accuracy                           0.78     44066\n",
      "   macro avg       0.78      0.75      0.76     44066\n",
      "weighted avg       0.78      0.78      0.77     44066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_train_class_report = classification_report(y_train['status_group'], preds_dtc_train[:, 1])\n",
    "print(dtc_train_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dtc_test = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81      6559\n",
      "           1       0.76      0.59      0.66      4458\n",
      "\n",
      "    accuracy                           0.76     11017\n",
      "   macro avg       0.76      0.73      0.74     11017\n",
      "weighted avg       0.76      0.76      0.75     11017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_test_class_report = classification_report(y_test['status_group'], preds_dtc_test[:, 1])\n",
    "print(dtc_test_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit a baseline Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rfc_baseline = RandomForestClassifier(max_depth=30, n_estimators=100)\n",
    "rfc_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds_rfc_baseline_train = rfc_baseline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_baseline_train_class_report = classification_report(y_train, preds_rfc_baseline_train)\n",
    "print(rfc_baseline_train_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds_rfc_baseline_test = rfc_baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_baseline_test_class_report = classification_report(y_test, preds_rfc_baseline_test)\n",
    "print(rfc_baseline_test_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "param_grid = {'max_depth':[50],\n",
    "             'n_estimators':[50],\n",
    "             }\n",
    "cv_rfc = GridSearchCV(rfc, param_grid, cv=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rfc_test = cv_rfc.predict(X_test) # predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Eval\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, preds_rfc_test))\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, preds_rfc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R-squared:', r2_score(y_test, preds_rfc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_best = cv_rfc.best_estimator_\n",
    "m_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare accuracy and feature importance of your\n",
    "## Gridsearch model and your baseline RandomForest model \n",
    "y_hat = m_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_grid_test_class_report = classification_report(y_test, y_hat)\n",
    "print(rfc_grid_test_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "tn = cm[0,0]\n",
    "tp = cm[1,1]\n",
    "fp = cm[0,1]\n",
    "fn = cm[1,0]\n",
    "sns.heatmap(cm, cmap='coolwarm', annot=True)\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('actuals')\n",
    "plt.savefig('img/confusion.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ((tp+tn)/(tp+tn+fp+fn))*100\n",
    "print('Accuracy : {}'.format(accuracy))\n",
    "recall = (tp/(fp+tp))*100\n",
    "print('Recall : {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
